{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from skimage.metrics import structural_similarity as ssim\n","from PIL import Image\n","\n","SEED = 42\n","np.random.ssed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load dataset\n","def load_data(directory):\n","    images = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n","            img_path = os.path.join(directory, filename)\n","            img = img.resize((28, 28))  # Resize to 28x28 if needed\n","            img = np.array(img) / 255.0  # Normalize\n","            images.append(img)\n","    images = np.expand_dims(images, axis=-1)  # Add channel dimension\n","    return np.array(images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the generator model\n","def build_generator():\n","    model = tf.keras.Sequential([\n","        layers.Dense(128, activation='relu', input_dim=100),\n","        layers.BatchNormalization(),\n","        layers.Dense(256, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Dense(512, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Dense(28 * 28 * 1, activation='tanh'),\n","        layers.Reshape((28, 28, 1))\n","    ])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the discriminator model\n","def build_discriminator():\n","    model = tf.keras.Sequential([\n","        layers.Flatten(input_shape=(28, 28, 1)),\n","        layers.Dense(512, activation='relu'),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(1, activation='sigmoid')\n","    ])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compile models\n","def compile_models(generator, discriminator):\n","    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    discriminator.trainable = False\n","\n","    gan_input = layers.Input(shape=(100,))\n","    generated_image = generator(gan_input)\n","    gan_output = discriminator(generated_image)\n","    gan = tf.keras.models.Model(gan_input, gan_output)\n","    gan.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","    return gan"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train the GAN\n","def train_gan(generator, discriminator, gan, data, epochs, batch_size=128):\n","    epochs = 10\n","    for epoch in range(epochs):\n","        for _ in range(data.shape[0] // batch_size):\n","            # Train discriminator\n","            noise = np.random.normal(0, 1, (batch_size, 100))\n","            generated_images = generator.predict(noise)\n","            real_images = data[np.random.randint(0, data.shape[0], batch_size)]\n","\n","            labels_real = np.ones((batch_size, 1))\n","            labels_fake = np.zeros((batch_size, 1))\n","\n","            d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n","            d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n","\n","            # Train generator\n","            noise = np.random.normal(0, 1, (batch_size, 100))\n","            labels_gan = np.ones((batch_size, 1))\n","\n","            g_loss = gan.train_on_batch(noise, labels_gan)\n","\n","        print(f\"Epoch {epoch + 1}/{epochs}, Discriminator Loss: {d_loss_real[0] + d_loss_fake[0]}, Generator Loss: {g_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Generate images and validate with SSIM\n","def validate_gan(generator, data, num_images=10):\n","    noise = np.random.normal(0, 1, (num_images, 100))\n","    generated_images = generator.predict(noise)\n","    real_images = data[np.random.randint(0, data.shape[0], num_images)]\n","\n","    ssim_scores = [ssim(real_images[i].reshape(28, 28), generated_images[i].reshape(28, 28)) for i in range(num_images)]\n","\n","    for i, score in enumerate(ssim_scores):\n","        print(f\"SSIM for image {i+1}: {score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Main function\n","def main():\n","    data = load_data('path_to_fitz_directory')\n","    generator = build_generator()\n","    discriminator = build_discriminator()\n","    gan = compile_models(generator, discriminator)\n","    train_gan(generator, discriminator, gan, data, epochs=10)\n","    validate_gan(generator, data)\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
